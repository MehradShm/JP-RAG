{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pATuaU9muktr",
    "outputId": "7c89866c-dac2-4649-cb0e-9cf26c4f1b01",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Downloading llama_index-0.10.58-py3-none-any.whl (6.8 kB)\n",
      "Collecting llama-index-agent-openai<0.3.0,>=0.1.4\n",
      "  Downloading llama_index_agent_openai-0.2.9-py3-none-any.whl (13 kB)\n",
      "Collecting llama-index-cli<0.2.0,>=0.1.2\n",
      "  Downloading llama_index_cli-0.1.13-py3-none-any.whl (27 kB)\n",
      "Collecting llama-index-core==0.10.58\n",
      "  Downloading llama_index_core-0.10.58-py3-none-any.whl (15.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting llama-index-embeddings-openai<0.2.0,>=0.1.5\n",
      "  Downloading llama_index_embeddings_openai-0.1.11-py3-none-any.whl (6.3 kB)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.2.0\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.2.7-py3-none-any.whl (9.5 kB)\n",
      "Collecting llama-index-legacy<0.10.0,>=0.9.48\n",
      "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting llama-index-llms-openai<0.2.0,>=0.1.27\n",
      "  Downloading llama_index_llms_openai-0.1.27-py3-none-any.whl (11 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.1.8-py3-none-any.whl (5.9 kB)\n",
      "Collecting llama-index-program-openai<0.2.0,>=0.1.3\n",
      "  Downloading llama_index_program_openai-0.1.7-py3-none-any.whl (5.3 kB)\n",
      "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2\n",
      "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
      "Collecting llama-index-readers-file<0.2.0,>=0.1.4\n",
      "  Downloading llama_index_readers_file-0.1.31-py3-none-any.whl (38 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.1.2\n",
      "  Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl (2.5 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from llama-index-core==0.10.58->llama-index) (6.0.1)\n",
      "Collecting SQLAlchemy[asyncio]>=1.4.49\n",
      "  Downloading SQLAlchemy-2.0.31-cp311-cp311-macosx_10_9_x86_64.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting aiohttp<4.0.0,>=3.8.6\n",
      "  Downloading aiohttp-3.9.5-cp311-cp311-macosx_10_9_x86_64.whl (402 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.4/402.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting dataclasses-json\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Collecting deprecated>=1.2.9.3\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Using cached fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Requirement already satisfied: httpx in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from llama-index-core==0.10.58->llama-index) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from llama-index-core==0.10.58->llama-index) (1.6.0)\n",
      "Collecting networkx>=3.0\n",
      "  Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting nltk<4.0.0,>=3.8.1\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting numpy<2.0.0\n",
      "  Downloading numpy-1.26.4-cp311-cp311-macosx_10_9_x86_64.whl (20.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting openai>=1.1.0\n",
      "  Downloading openai-1.37.0-py3-none-any.whl (337 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.0/337.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pandas\n",
      "  Downloading pandas-2.2.2-cp311-cp311-macosx_10_9_x86_64.whl (12.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pillow>=9.0.0\n",
      "  Downloading pillow-10.4.0-cp311-cp311-macosx_10_10_x86_64.whl (3.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.31.0 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from llama-index-core==0.10.58->llama-index) (2.32.3)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.2.0\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Collecting tiktoken>=0.3.3\n",
      "  Downloading tiktoken-0.7.0-cp311-cp311-macosx_10_9_x86_64.whl (961 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm<5.0.0,>=4.66.1\n",
      "  Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from llama-index-core==0.10.58->llama-index) (4.12.2)\n",
      "Collecting typing-inspect>=0.8.0\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting wrapt\n",
      "  Downloading wrapt-1.16.0-cp311-cp311-macosx_10_9_x86_64.whl (37 kB)\n",
      "Collecting llama-cloud>=0.0.11\n",
      "  Downloading llama_cloud-0.0.11-py3-none-any.whl (154 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
      "Collecting pypdf<5.0.0,>=4.0.1\n",
      "  Downloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting striprtf<0.0.27,>=0.0.26\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Collecting llama-parse>=0.4.0\n",
      "  Downloading llama_parse-0.4.9-py3-none-any.whl (9.4 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.58->llama-index) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.4.1-cp311-cp311-macosx_10_9_x86_64.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.5-cp311-cp311-macosx_10_9_x86_64.whl (30 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.4-cp311-cp311-macosx_10_9_x86_64.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n",
      "Collecting pydantic>=1.10\n",
      "  Downloading pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.9/423.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyio in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from httpx->llama-index-core==0.10.58->llama-index) (4.4.0)\n",
      "Requirement already satisfied: certifi in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from httpx->llama-index-core==0.10.58->llama-index) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from httpx->llama-index-core==0.10.58->llama-index) (1.0.5)\n",
      "Requirement already satisfied: idna in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from httpx->llama-index-core==0.10.58->llama-index) (3.7)\n",
      "Requirement already satisfied: sniffio in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from httpx->llama-index-core==0.10.58->llama-index) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core==0.10.58->llama-index) (0.14.0)\n",
      "Collecting click\n",
      "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting regex>=2021.8.3\n",
      "  Downloading regex-2024.7.24-cp311-cp311-macosx_10_9_x86_64.whl (282 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.1/282.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting distro<2,>=1.7.0\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core==0.10.58->llama-index) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core==0.10.58->llama-index) (2.2.2)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-3.0.3-cp311-cp311-macosx_11_0_universal2.whl (271 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.7/271.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting mypy-extensions>=0.3.0\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0\n",
      "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from pandas->llama-index-core==0.10.58->llama-index) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tzdata>=2022.7\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=17.0 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core==0.10.58->llama-index) (24.1)\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.20.1\n",
      "  Downloading pydantic_core-2.20.1-cp311-cp311-macosx_10_12_x86_64.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core==0.10.58->llama-index) (1.16.0)\n",
      "Installing collected packages: striprtf, pytz, dirtyjson, wrapt, tzdata, tqdm, tenacity, regex, pypdf, pydantic-core, pillow, numpy, networkx, mypy-extensions, multidict, marshmallow, joblib, greenlet, fsspec, frozenlist, distro, click, annotated-types, yarl, typing-inspect, tiktoken, SQLAlchemy, pydantic, pandas, nltk, deprecated, aiosignal, openai, llama-cloud, dataclasses-json, aiohttp, llama-index-legacy, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "Successfully installed SQLAlchemy-2.0.31 aiohttp-3.9.5 aiosignal-1.3.1 annotated-types-0.7.0 click-8.1.7 dataclasses-json-0.6.7 deprecated-1.2.14 dirtyjson-1.0.8 distro-1.9.0 frozenlist-1.4.1 fsspec-2024.6.1 greenlet-3.0.3 joblib-1.4.2 llama-cloud-0.0.11 llama-index-0.10.58 llama-index-agent-openai-0.2.9 llama-index-cli-0.1.13 llama-index-core-0.10.58 llama-index-embeddings-openai-0.1.11 llama-index-indices-managed-llama-cloud-0.2.7 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.27 llama-index-multi-modal-llms-openai-0.1.8 llama-index-program-openai-0.1.7 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.31 llama-index-readers-llama-parse-0.1.6 llama-parse-0.4.9 marshmallow-3.21.3 multidict-6.0.5 mypy-extensions-1.0.0 networkx-3.3 nltk-3.8.1 numpy-1.26.4 openai-1.37.0 pandas-2.2.2 pillow-10.4.0 pydantic-2.8.2 pydantic-core-2.20.1 pypdf-4.3.1 pytz-2024.1 regex-2024.7.24 striprtf-0.0.26 tenacity-8.5.0 tiktoken-0.7.0 tqdm-4.66.4 typing-inspect-0.9.0 tzdata-2024.1 wrapt-1.16.0 yarl-1.9.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting llama-index-embeddings-huggingface\n",
      "  Downloading llama_index_embeddings_huggingface-0.2.2-py3-none-any.whl (7.2 kB)\n",
      "Collecting huggingface-hub[inference]>=0.19.0\n",
      "  Downloading huggingface_hub-0.24.2-py3-none-any.whl (417 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.2/417.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from llama-index-embeddings-huggingface) (0.10.58)\n",
      "Collecting sentence-transformers>=2.6.1\n",
      "  Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Using cached filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.1)\n",
      "Requirement already satisfied: requests in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.12.2)\n",
      "Requirement already satisfied: aiohttp in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.9.5)\n",
      "Collecting minijinja>=1.0\n",
      "  Downloading minijinja-2.0.1-cp38-abi3-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.0.31)\n",
      "Requirement already satisfied: dataclasses-json in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.0.8)\n",
      "Requirement already satisfied: httpx in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.3)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.8.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.37.0)\n",
      "Requirement already satisfied: pandas in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.2.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (10.4.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.7.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.16.0)\n",
      "Collecting transformers<5.0.0,>=4.34.0\n",
      "  Downloading transformers-4.43.2-py3-none-any.whl (9.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch>=1.11.0\n",
      "  Downloading torch-2.2.2-cp311-none-macosx_10_9_x86_64.whl (150.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.8/150.8 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.1-cp311-cp311-macosx_10_9_x86_64.whl (12.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting scipy\n",
      "  Downloading scipy-1.14.0-cp311-cp311-macosx_10_9_x86_64.whl (39.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.1/39.1 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.9.4)\n",
      "Requirement already satisfied: click in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2024.7.24)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.8.2)\n",
      "Requirement already satisfied: sniffio in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.3.1)\n",
      "Requirement already satisfied: certifi in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.0.5)\n",
      "Requirement already satisfied: idna in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from requests->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from requests->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.0.3)\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.1.4)\n",
      "Collecting tokenizers<0.20,>=0.19\n",
      "  Downloading tokenizers-0.19.1-cp311-cp311-macosx_10_12_x86_64.whl (2.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.4.1\n",
      "  Using cached safetensors-0.4.3-cp311-cp311-macosx_10_12_x86_64.whl (415 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2024.1)\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.1.5)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, threadpoolctl, sympy, scipy, safetensors, minijinja, filelock, torch, scikit-learn, huggingface-hub, tokenizers, transformers, sentence-transformers, llama-index-embeddings-huggingface\n",
      "Successfully installed filelock-3.15.4 huggingface-hub-0.24.2 llama-index-embeddings-huggingface-0.2.2 minijinja-2.0.1 mpmath-1.3.0 safetensors-0.4.3 scikit-learn-1.5.1 scipy-1.14.0 sentence-transformers-3.0.1 sympy-1.13.1 threadpoolctl-3.5.0 tokenizers-0.19.1 torch-2.2.2 transformers-4.43.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting peft\n",
      "  Downloading peft-0.12.0-py3-none-any.whl (296 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from peft) (24.1)\n",
      "Requirement already satisfied: psutil in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from peft) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from peft) (2.2.2)\n",
      "Requirement already satisfied: transformers in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from peft) (4.43.2)\n",
      "Requirement already satisfied: tqdm in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from peft) (4.66.4)\n",
      "Collecting accelerate>=0.21.0\n",
      "  Downloading accelerate-0.33.0-py3-none-any.whl (315 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.1/315.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: safetensors in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from peft) (0.4.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from peft) (0.24.2)\n",
      "Requirement already satisfied: filelock in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\n",
      "Requirement already satisfied: requests in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: networkx in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from transformers->peft) (2024.7.24)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from transformers->peft) (0.19.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Installing collected packages: accelerate, peft\n",
      "Successfully installed accelerate-0.33.0 peft-0.12.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting auto-gptq\n",
      "  Downloading auto_gptq-0.7.1.tar.gz (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.1/126.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[7 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/52/ndsjzqdj151fqnz9g4cqmmw40000gn/T/pip-install-on1picn7/auto-gptq_d14f9d30b3a045589fe890efe4ebd851/setup.py\", line 62, in <module>\n",
      "  \u001b[31m   \u001b[0m     CUDA_VERSION = \"\".join(os.environ.get(\"CUDA_VERSION\", default_cuda_version).split(\".\"))\n",
      "  \u001b[31m   \u001b[0m                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m AttributeError: 'NoneType' object has no attribute 'split'\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[?25hCollecting optimum\n",
      "  Downloading optimum-1.21.2-py3-none-any.whl (424 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m424.7/424.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting coloredlogs\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sympy in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from optimum) (1.13.1)\n",
      "Collecting transformers[sentencepiece]<4.43.0,>=4.26.0\n",
      "  Downloading transformers-4.42.4-py3-none-any.whl (9.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.11 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from optimum) (2.2.2)\n",
      "Requirement already satisfied: packaging in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from optimum) (24.1)\n",
      "Requirement already satisfied: numpy<2.0 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from optimum) (1.26.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.8.0 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from optimum) (0.24.2)\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from huggingface-hub>=0.8.0->optimum) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from huggingface-hub>=0.8.0->optimum) (2024.6.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from huggingface-hub>=0.8.0->optimum) (6.0.1)\n",
      "Requirement already satisfied: requests in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from huggingface-hub>=0.8.0->optimum) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from huggingface-hub>=0.8.0->optimum) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from huggingface-hub>=0.8.0->optimum) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from torch>=1.11->optimum) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from torch>=1.11->optimum) (3.1.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from transformers[sentencepiece]<4.43.0,>=4.26.0->optimum) (2024.7.24)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from transformers[sentencepiece]<4.43.0,>=4.26.0->optimum) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from transformers[sentencepiece]<4.43.0,>=4.26.0->optimum) (0.19.1)\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-5.27.2-cp38-abi3-macosx_10_9_universal2.whl (412 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.2/412.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting sentencepiece!=0.1.92,>=0.1.91\n",
      "  Downloading sentencepiece-0.2.0-cp311-cp311-macosx_10_9_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting humanfriendly>=9.1\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyarrow>=15.0.0\n",
      "  Downloading pyarrow-17.0.0-cp311-cp311-macosx_10_15_x86_64.whl (29.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.0/29.0 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyarrow-hotfix\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0\n",
      "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from datasets->optimum) (2.2.2)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.4.1-cp311-cp311-macosx_10_9_x86_64.whl (31 kB)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec[http]<=2024.5.0,>=2023.1.0\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from datasets->optimum) (3.9.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from sympy->optimum) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from aiohttp->datasets->optimum) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from aiohttp->datasets->optimum) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from aiohttp->datasets->optimum) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from aiohttp->datasets->optimum) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from aiohttp->datasets->optimum) (1.9.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (2024.7.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from jinja2->torch>=1.11->optimum) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from pandas->datasets->optimum) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from pandas->datasets->optimum) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from pandas->datasets->optimum) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets->optimum) (1.16.0)\n",
      "Installing collected packages: sentencepiece, xxhash, pyarrow-hotfix, pyarrow, protobuf, humanfriendly, fsspec, dill, multiprocess, coloredlogs, transformers, datasets, optimum\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.6.1\n",
      "    Uninstalling fsspec-2024.6.1:\n",
      "      Successfully uninstalled fsspec-2024.6.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.43.2\n",
      "    Uninstalling transformers-4.43.2:\n",
      "      Successfully uninstalled transformers-4.43.2\n",
      "Successfully installed coloredlogs-15.0.1 datasets-2.20.0 dill-0.3.8 fsspec-2024.5.0 humanfriendly-10.0 multiprocess-0.70.16 optimum-1.21.2 protobuf-5.27.2 pyarrow-17.0.0 pyarrow-hotfix-0.6 sentencepiece-0.2.0 transformers-4.42.4 xxhash-3.4.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from bitsandbytes) (1.14.0)\n",
      "Requirement already satisfied: numpy<2.3,>=1.23.5 in /Users/mehrad/research/self/env/lib/python3.11/site-packages (from scipy->bitsandbytes) (1.26.4)\n",
      "Installing collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.42.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index\n",
    "!pip install llama-index-embeddings-huggingface\n",
    "!pip install peft\n",
    "!pip install auto-gptq\n",
    "!pip install optimum\n",
    "!pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/Users/mehrad/research/self/codes/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5b2N4hu1un-d"
   },
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings, SimpleDirectoryReader, VectorStoreIndex, StorageContext, SimpleKeywordTableIndex\n",
    "from llama_index.core.retrievers import BaseRetriever, VectorIndexRetriever, KeywordTableSimpleRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.schema import NodeWithScore\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "import torch\n",
    "import json\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "c_gPWw-pFmw9"
   },
   "outputs": [],
   "source": [
    "with open(\"/Users/mehrad/research/self/codes/data/battles_text_v2.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "mdTLsTNuF4tQ"
   },
   "outputs": [],
   "source": [
    "for battle in data:\n",
    "  with open(f\"{base_dir}/docs/{battle['title']}.json\", \"w\") as f:\n",
    "    json.dump(battle, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vPfOw0UZvR3_",
    "outputId": "8a84defb-c7b2-4747-a18d-722a096f3024",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be710a857c8c4beeac87e6d4567ce3f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20287f9ec05c47e49000be34ff0d3f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b783bf8e0d14f02a79b09cdf557e3d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/94.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e07a16faaad426386e5a5ee00b8ef0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b571b446e88a420597ee975b9a5fe1cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a3907ce94f24930a707250a2e5cbff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7c16dd295c0471792f0d84af780ac43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfa073c69aa248fab9be874d3f6c066a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "defdf6854b9844738bfc71e689988457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c3924bc5a64494e9c1e126c4717e7ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01b7258d78624bbd8ab4b1f52b0520ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM is explicitly disabled. Using MockLLM.\n"
     ]
    }
   ],
   "source": [
    "# import any embedding model on HF hub (https://huggingface.co/spaces/mteb/leaderboard)\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "# Settings.embed_model = HuggingFaceEmbedding(model_name=\"thenlper/gte-large\") # alternative model\n",
    "\n",
    "Settings.llm = None\n",
    "Settings.chunk_size = 192\n",
    "Settings.chunk_overlap = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "gnIFta8kyTXT"
   },
   "outputs": [],
   "source": [
    "reader = SimpleDirectoryReader(f\"{base_dir}/docs/\")\n",
    "documents = reader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "poFyJXKiFirg",
    "outputId": "e88653a3-0fa4-41fd-8ac5-cb5e4603792d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "456"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(document)\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "x22PadESnWhq"
   },
   "outputs": [],
   "source": [
    "keyword_index = SimpleKeywordTableIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "QLbdmTiZv2ap"
   },
   "outputs": [],
   "source": [
    "#query = \"who won the siege of osaka?\"\n",
    "query = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "a65s_B-cu3Xh"
   },
   "outputs": [],
   "source": [
    "keyword_retriever = KeywordTableSimpleRetriever(keyword_index, similarity_top_k=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "Ql1bY4WfyATq"
   },
   "outputs": [],
   "source": [
    "tmp = keyword_retriever.retrieve(query)\n",
    "tops = []\n",
    "for x in tmp:\n",
    "  tops.append({query:x.text})\n",
    "print(tops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "PWsnpqSj77Hs"
   },
   "outputs": [],
   "source": [
    "for i,x in enumerate(tops):\n",
    "  with open(f\"/Users/mehrad/research/self/codes/data/topdocs/{i}.json\", \"w\") as f:\n",
    "      json.dump(x, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "J8DFvzvu3DJB"
   },
   "outputs": [],
   "source": [
    "vsi = SimpleDirectoryReader(\"/Users/mehrad/research/self/codes/data//topdocs\")\n",
    "top_docs = vsi.load_data()\n",
    "vsi_index = VectorStoreIndex.from_documents(top_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "gBxOPL0T_DYi"
   },
   "outputs": [],
   "source": [
    "retriever = VectorIndexRetriever(\n",
    "    index=vsi_index,\n",
    "    similarity_top_k=5,\n",
    ")\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "q6CT35bYvvZv"
   },
   "outputs": [],
   "source": [
    "response = query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bWVWfPja_kOB",
    "outputId": "249cd6cf-147d-4309-98dd-d32d83826eb3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:\n",
      "{\"who won the siege of osaka?\": \"{\\\"title\\\": \\\"Siege of Akasaka\\\", \\\"paragraphs\\\": \\\"The  siege of Akasaka  was one of the earlier battles of the  Genk\\\\u014d War  between the figurehead  Emperor   Godaigo  and the largely  H\\\\u014dj\\\\u014d -controlled  Kamakura shogunate  during the final years of the  Kamakura period  in  Japan .\n",
      "\n",
      "{\"who won the siege of osaka?\": \"Hideyoshi's grave, along with Kyoto's  Toyokuni Shrine , were destroyed subsequently during the Tokugawa shogunate. Ch\\\\u014dsokabe Morichika was beheaded on May 11. There are also records of pillaging and mass rapes by Tokugawa forces at the closing of the siege. [ citation needed ] The  bakufu  obtained 650,000  koku  at  Osaka  and started rebuilding Osaka Castle. Osaka was then made a  han  (feudal domain), and given to  Matsudaira Tadayoshi .\"}\n",
      "\n",
      "{\"who won the siege of osaka?\": \"ISBN \\\\u00a0 462307689X . Sankyoden Editorial Office; Watanabe Seisuke (1982).  \\\\u6bdb\\\\u5229\\\\u8f1d\\\\u5143\\\\u537f\\\\u4f1d . \\\\u30de\\\\u30c4\\\\u30ce\\\\u66f8\\\\u5e97. \\\\uff08first published in 1944\\\\uff09 Media related to  Siege of Osaka  at Wikimedia Commons Israel United States Japan\\\"}\"}\n",
      "\n",
      "{\"who won the siege of osaka?\": \"{\\\"title\\\": \\\"Siege of Osaka\\\", \\\"paragraphs\\\": \\\"Tokugawa shogunate  and its loyalist banners: Toyotomi clan  and its loyalist banners: The  siege of Osaka  ( \\\\u5927\\\\u5742\\\\u306e\\\\u5f79 ,  \\\\u014csaka no Eki , or, more commonly, \\\\u5927\\\\u5742\\\\u306e\\\\u9663  \\\\u014csaka no Jin )  was a series of battles undertaken by the Japanese  Tokugawa shogunate  against the  Toyotomi clan , and ending in that clan's destruction. Divided into two stages, the winter campaign and the summer campaign, it lasted from 1614 to 1615.\"}\n",
      "\n",
      "{\"who won the siege of osaka?\": \"v t e Terabe Marune Okehazama Azukizaka Kakegawa Kanegasaki Anegawa Futamata Mikatagahara Takatenjin Yoshida Nagashino Temmokuzan Takat\\\\u014d Tensh\\\\u014d-Jingo Komaki and Nagakute Kanie Ueda Odawara Kunohe Sekigahara Osaka v t e Norada Kanegasaki Anegawa Mount Hiei Hikida Castle Ichij\\\\u014ddani Castle Odani Castle Siege of Kanegasaki (1337) Turnbull, Stephen (1998). 'The Samurai Sourcebook'. London: Cassell & Co. v t e\\\"}\"}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "context_texts = [x.text for x in response.source_nodes]\n",
    "context = \"Context:\\n\"\n",
    "for i in range(min(5, len(response.source_nodes))):\n",
    "    context = context + response.source_nodes[i].text + \"\\n\\n\"\n",
    "\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241,
     "referenced_widgets": [
      "3df6d71d26e64e52bf4bf2d3e7219ed9",
      "12e9768e3e4248488c9107448304469e",
      "cc369449ffff43deb63f4a3412e18b03",
      "d5f28c59c40b41abb5251f918d209d8e",
      "7aa3b16f025f4fcfb5ce7607734650de",
      "01e4a0069c6044b59648f74482f0960b",
      "8a9fe0c1f01648b682e1fc76304ac1e3",
      "367025ffd0974fb8b152243c87e9fd53",
      "62d656ee7be5498389d2c913a2335bfc",
      "d69b1b7cc42e4ddfb5bf82a90cec54bf",
      "396d5bf0883e426c9acd44a9b8167573",
      "8ee92b0505324c8f88f6671410515941",
      "b8f229c1db6b4a71bd55314444496722",
      "2dd0d302af104bea9539b4e44757d048",
      "5f8b19799c5c442b95a3ea8f0f934901",
      "37e87a29318d443bad1b2d4268735018",
      "1194b9a4b2d344ad850b45c8db1addb7",
      "0a7fac45ae4b42c9a3a9e105dafe36a4",
      "1126ae7921544e058538f65cc2824530",
      "abbb7c1a04a74fbe8c0d502f37585bbe",
      "10edc1ac4e244ab99ed033d47658beff",
      "e2f93dc6476b4163bd0c343d7ef0a1ef",
      "adf716d0a3574f71aa2ae56fa946ebf3",
      "f1f6207f4e9341dfb6504dee0203ddb6",
      "191c9012b0e24268a78989a2e5af155d",
      "417be49afccd484bacc47bd73a2bc3c5",
      "f526cb7ab7b643c4ac199f235123d7b7",
      "458e2e308fde4f688a0ec867beddea49",
      "1fa53b1b77354089a72ebc464d831796",
      "88506f0c04b940fb8603f354f4596484",
      "c19c359f865747ad863985adc7288cc8",
      "65ab520ed10e40359e5d30fdf61dbcd3",
      "715cc9818b1349ba83e6c727b86ff660",
      "829264da9f2d4984b7e8bef95c7e23f1",
      "559586527d3d461b92af4dbadd7b6691",
      "8af6337235fa4f849567a056feecf617",
      "f2877dfb910641ae8ac4af8afdc47ef1",
      "131eee872af84054a510c0e9816ffcc1",
      "a7c032c335c746f489e3e9cdc26745a9",
      "fd6e6129457842a29fc1306451c323dd",
      "3abd55f76b5e43a3a59d32cb80784f9b",
      "ee063e069bd54cd6b04c28b98994e1dd",
      "a2bda5e229664440b18c1dcae58c0521",
      "9c319e6538134d128b82ba57f2363ba7",
      "b4877310232e4459b515302559063c11",
      "491a70f4874a4fd9979f76d0bff03b07",
      "bd2552df16964f28a3de2c11a895ae12",
      "59b7e72db7c8427ab0a7d0af326baa53",
      "537e6f67094843d18bf9558df8fe64d8",
      "f286947f27704ca0b17983da5bee9ec2",
      "e4eb74bd4f6a4db29c725cc78a37c7e0",
      "08ff2d2291474915a2f4e654ba8c3376",
      "e61e6a8645dd449984a74bc8549b562f",
      "708f0750b5b148ffa9af4034c2f1de14",
      "7dbf031ef5eb4ba79a70f7a1ec6e15b6",
      "c840f95653e84e999011bd481e5d8881",
      "f0cefb763aa94a209afc519404be0937",
      "9b501878974e40cba80b6c1720136f53",
      "947b1247612a4b749d47ec642038b55f",
      "c522b77d01134c649471efe63081b70a",
      "7e338023bb864b179d90885a058cbd20",
      "cb16691066414234b3fe425cc2672009",
      "0d9419b927df48aca7d3c47da384ffcf",
      "0f85b6a7d2e94192a38a364aa6745797",
      "1acadc8baca84d5f8426d95892ee61c9",
      "a2824386ffe54048b67970b1dec4c396",
      "8269d6e2a38f41128760c406790449f8",
      "c2bbd2008ab54d04ae7fe777c8294872",
      "ea3ca0e907a347a192639933cfd62b0e",
      "33eeb4943e0d4041b04ec19239737d3b",
      "75b5bfa9bf3d4deabf014fa30f064797",
      "09f676debebe4f4fa566d3a12fbc74db",
      "aa9e1adbb03145bf9f7303f483ef092d",
      "52932579c6534df1a3ff5917e56a9da4",
      "46cdfb91bdd24b1098ffaf3e372212b7",
      "e9a69dd13c45432eaf46e81c6932fa37",
      "1b16f3a226f84ea68d75e266dfe3a9c0"
     ]
    },
    "id": "7UTsAvHTDO0r",
    "outputId": "3df2b252-330d-4a75-da31-8be63dfd921e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/xLAM-1b-fc-r\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Salesforce/xLAM-1b-fc-r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oP8aro9gKpYs",
    "outputId": "07fd759f-d43c-4c2d-d0b3-3358ae93b8d0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "i1mhiOu-LEw_"
   },
   "outputs": [],
   "source": [
    "prompt_template = lambda comment: f\"\"\"[INST]JP Historian, functioning as a Japanese history expert, communicates in clear, accessible language. \\\n",
    "It responsts to queries aptly and ends responses with its signature '–JP_Historian'. \\\n",
    "JP Historian already knows many things, but it will also be given a context over the query.  \\\n",
    "JP Historian tries to provide comprehensive responses, yet conscise and only contain relevant information thus keeping the interaction natural and easy.\n",
    "\n",
    "Please respond to the following query. Use the context above if it is helpful.\n",
    "\n",
    "{comment}\n",
    "[/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "wZRK6mKgIfJw"
   },
   "outputs": [],
   "source": [
    "prompt_template_w_context = lambda context, comment: f\"\"\"[INST]JP Historian, functioning as a Japanese history expert, communicates in clear, accessible language. \\\n",
    "It responsts to queries aptly and ends responses with its signature '–JP_Historian'. \\\n",
    "JP Historian already knows many things, but it will also be given a context over the query. If the context was relevant and useful, it may use it to generate its response. \\\n",
    "It tries to provide comprehensive responses, yet conscise and only contain relevant information thus keeping the interaction natural and easy.\n",
    "\n",
    "{context}\n",
    "\n",
    "Please respond to the following query. Use the context above if it is helpful.\n",
    "\n",
    "{comment}\n",
    "[/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "id": "ix7oY6n3Lf1T"
   },
   "outputs": [],
   "source": [
    "normal_template = lambda context, comment: f\"\"\"[INST]\n",
    "JP Historian, functioning as a Japanese history expert, communicates in clear, accessible language. \\\n",
    "use the context below if it is helpful.\n",
    "\n",
    "{context}\n",
    "\n",
    "Please respond to the following query. Use the context above if it is helpful, but rephrase them, don't include them directrly.\n",
    "\n",
    "{comment}\n",
    "[/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "nocon_template = lambda comment: f\"\"\"[INST]\n",
    "JP Historian, functioning as a Japanese history expert, communicates in clear, accessible language. \\\n",
    "Please respond to the following query. \n",
    "{comment}\n",
    "[/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "promptWcontext, promptNcontext = prompt_template_w_context(context, query), prompt_template(query)\n",
    "normalPrompt = normal_template(context, query)\n",
    "noconPrompt = nocon_template(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<｜begin▁of▁sentence｜>[INST]JP Historian, functioning as a Japanese history expert, communicates in clear, accessible language. It responsts to queries aptly and ends responses with its signature '–JP_Historian'. JP Historian already knows many things, but it will also be given a context over the query.  JP Historian tries to provide comprehensive responses, yet conscise and only contain relevant information thus keeping the interaction natural and easy.\n",
      "\n",
      "Please respond to the following query. Use the context above if it is helpful.\n",
      "\n",
      "who won the siege of osaka?\n",
      "[/INST]\n",
      "\n",
      "I'm sorry, but I couldn't find any information about the history of the siege of Osaka. Is there anything else I can help you with?\n",
      "<|EOT|>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs = tokenizer(promptNcontext, return_tensors=\"pt\")\n",
    "outputs = model.generate(input_ids=inputs[\"input_ids\"], max_new_tokens=280)\n",
    "\n",
    "print(tokenizer.batch_decode(outputs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "id": "umppS5cqIpHA",
    "outputId": "592dd1ac-6c59-4e8b-961a-f56f8ba5e7dd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<｜begin▁of▁sentence｜>[INST]\n",
      "JP Historian, functioning as a Japanese history expert, communicates in clear, accessible language. use the context below if it is helpful.\n",
      "\n",
      "Context:\n",
      "{\"who won the siege of osaka?\": \"{\\\"title\\\": \\\"Siege of Akasaka\\\", \\\"paragraphs\\\": \\\"The  siege of Akasaka  was one of the earlier battles of the  Genk\\\\u014d War  between the figurehead  Emperor   Godaigo  and the largely  H\\\\u014dj\\\\u014d -controlled  Kamakura shogunate  during the final years of the  Kamakura period  in  Japan .\n",
      "\n",
      "{\"who won the siege of osaka?\": \"Hideyoshi's grave, along with Kyoto's  Toyokuni Shrine , were destroyed subsequently during the Tokugawa shogunate. Ch\\\\u014dsokabe Morichika was beheaded on May 11. There are also records of pillaging and mass rapes by Tokugawa forces at the closing of the siege. [ citation needed ] The  bakufu  obtained 650,000  koku  at  Osaka  and started rebuilding Osaka Castle. Osaka was then made a  han  (feudal domain), and given to  Matsudaira Tadayoshi .\"}\n",
      "\n",
      "{\"who won the siege of osaka?\": \"ISBN \\\\u00a0 462307689X . Sankyoden Editorial Office; Watanabe Seisuke (1982).  \\\\u6bdb\\\\u5229\\\\u8f1d\\\\u5143\\\\u537f\\\\u4f1d . \\\\u30de\\\\u30c4\\\\u30ce\\\\u66f8\\\\u5e97. \\\\uff08first published in 1944\\\\uff09 Media related to  Siege of Osaka  at Wikimedia Commons Israel United States Japan\\\"}\"}\n",
      "\n",
      "{\"who won the siege of osaka?\": \"{\\\"title\\\": \\\"Siege of Osaka\\\", \\\"paragraphs\\\": \\\"Tokugawa shogunate  and its loyalist banners: Toyotomi clan  and its loyalist banners: The  siege of Osaka  ( \\\\u5927\\\\u5742\\\\u306e\\\\u5f79 ,  \\\\u014csaka no Eki , or, more commonly, \\\\u5927\\\\u5742\\\\u306e\\\\u9663  \\\\u014csaka no Jin )  was a series of battles undertaken by the Japanese  Tokugawa shogunate  against the  Toyotomi clan , and ending in that clan's destruction. Divided into two stages, the winter campaign and the summer campaign, it lasted from 1614 to 1615.\"}\n",
      "\n",
      "{\"who won the siege of osaka?\": \"v t e Terabe Marune Okehazama Azukizaka Kakegawa Kanegasaki Anegawa Futamata Mikatagahara Takatenjin Yoshida Nagashino Temmokuzan Takat\\\\u014d Tensh\\\\u014d-Jingo Komaki and Nagakute Kanie Ueda Odawara Kunohe Sekigahara Osaka v t e Norada Kanegasaki Anegawa Mount Hiei Hikida Castle Ichij\\\\u014ddani Castle Odani Castle Siege of Kanegasaki (1337) Turnbull, Stephen (1998). 'The Samurai Sourcebook'. London: Cassell & Co. v t e\\\"}\"}\n",
      "\n",
      "\n",
      "\n",
      "Please respond to the following query. Use the context above if it is helpful.\n",
      "\n",
      "who won the siege of osaka?\n",
      "[/INST]\n",
      "\n",
      "{\"answer\": \"The siege of Osaka was fought by the Tokugawa shogunate against the Toyotomi clan. It lasted from 1614 to 1615.\"}<|EOT|>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs = tokenizer(normalPrompt, return_tensors=\"pt\")\n",
    "outputs = model.generate(input_ids=inputs[\"input_ids\"], max_new_tokens=280)\n",
    "\n",
    "print(tokenizer.batch_decode(outputs)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pPFUPZjWI_bI"
   },
   "source": [
    "## Create a custom retriver class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGModule():\n",
    "  \n",
    "    def __init__(self, docs_path, embedding_model = \"BAAI/bge-small-en-v1.5\",\n",
    "                 chunk_size = 192, chunk_overlap=24,\n",
    "                 keyword_topk = 15, vector_topk = 5):\n",
    "        self.initialize_settings(embedding_model, chunk_size, chunk_overlap)\n",
    "        \n",
    "        reader = SimpleDirectoryReader(docs_path)\n",
    "        documents = reader.load_data()\n",
    "        self.keyword_index = SimpleKeywordTableIndex.from_documents(documents)\n",
    "        # self.vector_index = VectorStoreIndex.from_documents(documents)\n",
    "        self.keyword_retriever = KeywordTableSimpleRetriever(keyword_index, similarity_top_k=keyword_topk)\n",
    "\n",
    "    def initialize_settings(self, embedding_model, chunk_size, chunk_overlap):\n",
    "        Settings.embed_model = HuggingFaceEmbedding(model_name=embedding_model)\n",
    "        Settings.llm = None\n",
    "        Settings.chunk_size = 192\n",
    "        Settings.chunk_overlap = 24\n",
    "\n",
    "    def apply_semantic_search(self, source_path, query):\n",
    "        vsi = SimpleDirectoryReader(\"/Users/mehrad/research/self/codes/data/topdocs\")\n",
    "        top_docs = vsi.load_data()\n",
    "        vsi_index = VectorStoreIndex.from_documents(top_docs)\n",
    "\n",
    "        vector_retriever = VectorIndexRetriever(\n",
    "                    index=vsi_index,\n",
    "                    similarity_top_k=5)\n",
    "        query_engine = RetrieverQueryEngine(\n",
    "                    retriever=vector_retriever,\n",
    "        )\n",
    "\n",
    "        semantic_response = query_engine.query(query)\n",
    "        return semantic_response\n",
    "\n",
    "    def retrieve(self, query, dest_path = f\"/Users/mehrad/research/self/codes/data/topdocs\"):\n",
    "        result = self.keyword_retriever.retrieve(query)\n",
    "        top_results = []\n",
    "        for x in result:\n",
    "            top_results.append({query:x.text})\n",
    "        for i,x in enumerate(top_results):\n",
    "          with open(f\"{dest_path}/{i}.json\", \"w\") as f:\n",
    "              json.dump(x, f)\n",
    "\n",
    "        semantic_response = self.apply_semantic_search(dest_path, query)\n",
    "\n",
    "        context_texts = [x.text for x in semantic_response.source_nodes]\n",
    "        context = \"Context:\\n\"\n",
    "        for i in range(min(5, len(context_texts))):\n",
    "            context = context + semantic_response.source_nodes[i].text + \"\\n\\n\"\n",
    "        return context\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM is explicitly disabled. Using MockLLM.\n"
     ]
    }
   ],
   "source": [
    "rag = RAGModule(docs_path = f\"{base_dir}/docs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " battle of miyajima\n"
     ]
    }
   ],
   "source": [
    "query = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = rag.retrieve(query = query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Context:\\n{\"battle of miyajima\": \"In 1554,  M\\\\\\\\u014dri Motonari , as a vassal of the \\\\\\\\u014cuchi clan, wanted to avenge the betrayed Yoshitaka, and so he rebelled against Sue, whose territorial ambitions were depleting clan resources.  The heavily outnumbered force under M\\\\\\\\u014dri attacked and defeated Sue at the  Battle of Oshikibata .  M\\\\\\\\u014dri then departed from the mainland to build a fort, known as  Miyao Castle , on Miyajima while proclaiming publicly his woe that it would not hold out long against an attack. [3] Miyao Castle was built on a hill near  Itsukushima Shrine  and facing the mainland, making it a visible and tempting target.\"}\\n\\n{\"battle of miyajima\": \"[5]   Sue Harukata escaped from the confines of Miyao Castle, but when he saw that escape from the island was not possible, he also committed suicide by  seppuku . [2] [6]  The \\\\\\\\u014cuchi clan\\'s senior vassal  Hironaka Takakane  fought, together with his son, to the end, and he was also killed. [7] The Sue forces at Miyajima are estimated to have been about 20,000 to 30,000 men, and though estimates of the combined forces under M\\\\\\\\u014dri Motonari range widely from 4,000 to 10,000 troops, [3] [4]  it is clear that M\\\\\\\\u014dri was heavily outnumbered.\"}\\n\\n{\"battle of miyajima\": \"{\\\\\"title\\\\\": \\\\\"Battle of Miyajima\\\\\", \\\\\"paragraphs\\\\\": \\\\\"The 1555  Battle of Miyajima  ( \\\\\\\\u53b3\\\\\\\\u5cf6\\\\\\\\u5408\\\\\\\\u6226 ,  Itsukushima Kassen ) [1]  was the only battle to be fought on the sacred island of  Miyajima ; the entire island is considered to be a  Shinto shrine , and no birth or death is allowed on the island. Extensive purification rituals took place after the battle, to cleanse the shrine and the island of the pollution of death.\\n\\n{\"battle of miyajima\": \"It was the first major conflict to occur following the  Battle of Wuhan . Following the  Fall of Nanjing , the  Imperial Japanese Navy Air Force  launched long-distance pre-emptive strikes from newly captured airbases in Nanjing against targets in Nanchang, including the primary  Chinese Air Force  base at  Qingyunpu .\"}\\n\\n{\"battle of miyajima\": \"Sue commandeered a fleet of merchant vessels and prepared the troops of the \\\\\\\\u014cuchi clan to cross the channel.  In the early hours of 15 October, Sue attacked  Miyao Castle  in an  amphibious   frontal assault . [3]   Meanwhile, M\\\\\\\\u014dri took advantage of his absence to seize  Sakurao Castle , Sue\\'s castle on the mainland. [4] With an embarkation point secured, M\\\\\\\\u014dri Motonari continued with his elaborate plan. He had enlisted the aid of the Noshima Murakami, a gang of local pirates led by  Murakami Takeyoshi , who agreed to transport the M\\\\\\\\u014dri troops to Miyajima.\"}\\n\\n'"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "promptWcontext, promptNcontext = prompt_template_w_context(info, query), prompt_template(query)\n",
    "normalPrompt = normal_template(info, query)\n",
    "noconPrompt = nocon_template(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<｜begin▁of▁sentence｜>[INST]JP Historian, functioning as a Japanese history expert, communicates in clear, accessible language. It responsts to queries aptly and ends responses with its signature '–JP_Historian'. JP Historian already knows many things, but it will also be given a context over the query.  JP Historian tries to provide comprehensive responses, yet conscise and only contain relevant information thus keeping the interaction natural and easy.\n",
      "\n",
      "Please respond to the following query. Use the context above if it is helpful.\n",
      "\n",
      "battle of miyajima\n",
      "[/INST]\n",
      "\n",
      "I'm sorry, but I couldn't find any information about the Battle of Miyajima. Is there anything else I can help you with?\n",
      "<|EOT|>\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(promptNcontext, return_tensors=\"pt\")\n",
    "outputs = model.generate(input_ids=inputs[\"input_ids\"], attention_mask = inputs['attention_mask'], max_new_tokens=280)\n",
    "\n",
    "print(tokenizer.batch_decode(outputs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:32021 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<｜begin▁of▁sentence｜>[INST]\n",
      "JP Historian, functioning as a Japanese history expert, communicates in clear, accessible language. use the context below if it is helpful.\n",
      "\n",
      "Context:\n",
      "{\"battle of miyajima\": \"In 1554,  M\\\\u014dri Motonari , as a vassal of the \\\\u014cuchi clan, wanted to avenge the betrayed Yoshitaka, and so he rebelled against Sue, whose territorial ambitions were depleting clan resources.  The heavily outnumbered force under M\\\\u014dri attacked and defeated Sue at the  Battle of Oshikibata .  M\\\\u014dri then departed from the mainland to build a fort, known as  Miyao Castle , on Miyajima while proclaiming publicly his woe that it would not hold out long against an attack. [3] Miyao Castle was built on a hill near  Itsukushima Shrine  and facing the mainland, making it a visible and tempting target.\"}\n",
      "\n",
      "{\"battle of miyajima\": \"[5]   Sue Harukata escaped from the confines of Miyao Castle, but when he saw that escape from the island was not possible, he also committed suicide by  seppuku . [2] [6]  The \\\\u014cuchi clan's senior vassal  Hironaka Takakane  fought, together with his son, to the end, and he was also killed. [7] The Sue forces at Miyajima are estimated to have been about 20,000 to 30,000 men, and though estimates of the combined forces under M\\\\u014dri Motonari range widely from 4,000 to 10,000 troops, [3] [4]  it is clear that M\\\\u014dri was heavily outnumbered.\"}\n",
      "\n",
      "{\"battle of miyajima\": \"{\\\"title\\\": \\\"Battle of Miyajima\\\", \\\"paragraphs\\\": \\\"The 1555  Battle of Miyajima  ( \\\\u53b3\\\\u5cf6\\\\u5408\\\\u6226 ,  Itsukushima Kassen ) [1]  was the only battle to be fought on the sacred island of  Miyajima ; the entire island is considered to be a  Shinto shrine , and no birth or death is allowed on the island. Extensive purification rituals took place after the battle, to cleanse the shrine and the island of the pollution of death.\n",
      "\n",
      "{\"battle of miyajima\": \"It was the first major conflict to occur following the  Battle of Wuhan . Following the  Fall of Nanjing , the  Imperial Japanese Navy Air Force  launched long-distance pre-emptive strikes from newly captured airbases in Nanjing against targets in Nanchang, including the primary  Chinese Air Force  base at  Qingyunpu .\"}\n",
      "\n",
      "{\"battle of miyajima\": \"Sue commandeered a fleet of merchant vessels and prepared the troops of the \\\\u014cuchi clan to cross the channel.  In the early hours of 15 October, Sue attacked  Miyao Castle  in an  amphibious   frontal assault . [3]   Meanwhile, M\\\\u014dri took advantage of his absence to seize  Sakurao Castle , Sue's castle on the mainland. [4] With an embarkation point secured, M\\\\u014dri Motonari continued with his elaborate plan. He had enlisted the aid of the Noshima Murakami, a gang of local pirates led by  Murakami Takeyoshi , who agreed to transport the M\\\\u014dri troops to Miyajima.\"}\n",
      "\n",
      "\n",
      "\n",
      "Please respond to the following query. Use the context above if it is helpful, but rephrase them, don't include them directrly.\n",
      "\n",
      "battle of miyajima\n",
      "[/INST]\n",
      "<|EOT|>\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(normalPrompt, return_tensors=\"pt\")\n",
    "outputs = model.generate(input_ids=inputs[\"input_ids\"], attention_mask = inputs['attention_mask'], max_new_tokens=800)\n",
    "\n",
    "print(tokenizer.batch_decode(outputs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01e4a0069c6044b59648f74482f0960b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08ff2d2291474915a2f4e654ba8c3376": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "09f676debebe4f4fa566d3a12fbc74db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0a7fac45ae4b42c9a3a9e105dafe36a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0d9419b927df48aca7d3c47da384ffcf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f85b6a7d2e94192a38a364aa6745797": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "10edc1ac4e244ab99ed033d47658beff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1126ae7921544e058538f65cc2824530": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1194b9a4b2d344ad850b45c8db1addb7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12e9768e3e4248488c9107448304469e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_01e4a0069c6044b59648f74482f0960b",
      "placeholder": "​",
      "style": "IPY_MODEL_8a9fe0c1f01648b682e1fc76304ac1e3",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "131eee872af84054a510c0e9816ffcc1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "191c9012b0e24268a78989a2e5af155d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88506f0c04b940fb8603f354f4596484",
      "max": 2424064,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c19c359f865747ad863985adc7288cc8",
      "value": 2424064
     }
    },
    "1acadc8baca84d5f8426d95892ee61c9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b16f3a226f84ea68d75e266dfe3a9c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1fa53b1b77354089a72ebc464d831796": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2dd0d302af104bea9539b4e44757d048": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1126ae7921544e058538f65cc2824530",
      "max": 791656,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_abbb7c1a04a74fbe8c0d502f37585bbe",
      "value": 791656
     }
    },
    "33eeb4943e0d4041b04ec19239737d3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e9a69dd13c45432eaf46e81c6932fa37",
      "placeholder": "​",
      "style": "IPY_MODEL_1b16f3a226f84ea68d75e266dfe3a9c0",
      "value": " 147/147 [00:00&lt;00:00, 3.94kB/s]"
     }
    },
    "367025ffd0974fb8b152243c87e9fd53": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "37e87a29318d443bad1b2d4268735018": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "396d5bf0883e426c9acd44a9b8167573": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3abd55f76b5e43a3a59d32cb80784f9b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3df6d71d26e64e52bf4bf2d3e7219ed9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_12e9768e3e4248488c9107448304469e",
       "IPY_MODEL_cc369449ffff43deb63f4a3412e18b03",
       "IPY_MODEL_d5f28c59c40b41abb5251f918d209d8e"
      ],
      "layout": "IPY_MODEL_7aa3b16f025f4fcfb5ce7607734650de"
     }
    },
    "417be49afccd484bacc47bd73a2bc3c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_65ab520ed10e40359e5d30fdf61dbcd3",
      "placeholder": "​",
      "style": "IPY_MODEL_715cc9818b1349ba83e6c727b86ff660",
      "value": " 2.42M/2.42M [00:00&lt;00:00, 2.83MB/s]"
     }
    },
    "458e2e308fde4f688a0ec867beddea49": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46cdfb91bdd24b1098ffaf3e372212b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "491a70f4874a4fd9979f76d0bff03b07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f286947f27704ca0b17983da5bee9ec2",
      "placeholder": "​",
      "style": "IPY_MODEL_e4eb74bd4f6a4db29c725cc78a37c7e0",
      "value": "config.json: 100%"
     }
    },
    "52932579c6534df1a3ff5917e56a9da4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "537e6f67094843d18bf9558df8fe64d8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "559586527d3d461b92af4dbadd7b6691": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a7c032c335c746f489e3e9cdc26745a9",
      "placeholder": "​",
      "style": "IPY_MODEL_fd6e6129457842a29fc1306451c323dd",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "59b7e72db7c8427ab0a7d0af326baa53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_708f0750b5b148ffa9af4034c2f1de14",
      "placeholder": "​",
      "style": "IPY_MODEL_7dbf031ef5eb4ba79a70f7a1ec6e15b6",
      "value": " 662/662 [00:00&lt;00:00, 9.67kB/s]"
     }
    },
    "5f8b19799c5c442b95a3ea8f0f934901": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_10edc1ac4e244ab99ed033d47658beff",
      "placeholder": "​",
      "style": "IPY_MODEL_e2f93dc6476b4163bd0c343d7ef0a1ef",
      "value": " 792k/792k [00:00&lt;00:00, 1.95MB/s]"
     }
    },
    "62d656ee7be5498389d2c913a2335bfc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "65ab520ed10e40359e5d30fdf61dbcd3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "708f0750b5b148ffa9af4034c2f1de14": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "715cc9818b1349ba83e6c727b86ff660": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "75b5bfa9bf3d4deabf014fa30f064797": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7aa3b16f025f4fcfb5ce7607734650de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7dbf031ef5eb4ba79a70f7a1ec6e15b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7e338023bb864b179d90885a058cbd20": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8269d6e2a38f41128760c406790449f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c2bbd2008ab54d04ae7fe777c8294872",
       "IPY_MODEL_ea3ca0e907a347a192639933cfd62b0e",
       "IPY_MODEL_33eeb4943e0d4041b04ec19239737d3b"
      ],
      "layout": "IPY_MODEL_75b5bfa9bf3d4deabf014fa30f064797"
     }
    },
    "829264da9f2d4984b7e8bef95c7e23f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_559586527d3d461b92af4dbadd7b6691",
       "IPY_MODEL_8af6337235fa4f849567a056feecf617",
       "IPY_MODEL_f2877dfb910641ae8ac4af8afdc47ef1"
      ],
      "layout": "IPY_MODEL_131eee872af84054a510c0e9816ffcc1"
     }
    },
    "88506f0c04b940fb8603f354f4596484": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a9fe0c1f01648b682e1fc76304ac1e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8af6337235fa4f849567a056feecf617": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3abd55f76b5e43a3a59d32cb80784f9b",
      "max": 2201,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ee063e069bd54cd6b04c28b98994e1dd",
      "value": 2201
     }
    },
    "8ee92b0505324c8f88f6671410515941": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b8f229c1db6b4a71bd55314444496722",
       "IPY_MODEL_2dd0d302af104bea9539b4e44757d048",
       "IPY_MODEL_5f8b19799c5c442b95a3ea8f0f934901"
      ],
      "layout": "IPY_MODEL_37e87a29318d443bad1b2d4268735018"
     }
    },
    "947b1247612a4b749d47ec642038b55f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1acadc8baca84d5f8426d95892ee61c9",
      "placeholder": "​",
      "style": "IPY_MODEL_a2824386ffe54048b67970b1dec4c396",
      "value": " 3.13G/3.13G [00:41&lt;00:00, 84.4MB/s]"
     }
    },
    "9b501878974e40cba80b6c1720136f53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d9419b927df48aca7d3c47da384ffcf",
      "max": 3132668804,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0f85b6a7d2e94192a38a364aa6745797",
      "value": 3132668804
     }
    },
    "9c319e6538134d128b82ba57f2363ba7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a2824386ffe54048b67970b1dec4c396": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a2bda5e229664440b18c1dcae58c0521": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a7c032c335c746f489e3e9cdc26745a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aa9e1adbb03145bf9f7303f483ef092d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "abbb7c1a04a74fbe8c0d502f37585bbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "adf716d0a3574f71aa2ae56fa946ebf3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f1f6207f4e9341dfb6504dee0203ddb6",
       "IPY_MODEL_191c9012b0e24268a78989a2e5af155d",
       "IPY_MODEL_417be49afccd484bacc47bd73a2bc3c5"
      ],
      "layout": "IPY_MODEL_f526cb7ab7b643c4ac199f235123d7b7"
     }
    },
    "b4877310232e4459b515302559063c11": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_491a70f4874a4fd9979f76d0bff03b07",
       "IPY_MODEL_bd2552df16964f28a3de2c11a895ae12",
       "IPY_MODEL_59b7e72db7c8427ab0a7d0af326baa53"
      ],
      "layout": "IPY_MODEL_537e6f67094843d18bf9558df8fe64d8"
     }
    },
    "b8f229c1db6b4a71bd55314444496722": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1194b9a4b2d344ad850b45c8db1addb7",
      "placeholder": "​",
      "style": "IPY_MODEL_0a7fac45ae4b42c9a3a9e105dafe36a4",
      "value": "spiece.model: 100%"
     }
    },
    "bd2552df16964f28a3de2c11a895ae12": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08ff2d2291474915a2f4e654ba8c3376",
      "max": 662,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e61e6a8645dd449984a74bc8549b562f",
      "value": 662
     }
    },
    "c19c359f865747ad863985adc7288cc8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c2bbd2008ab54d04ae7fe777c8294872": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_09f676debebe4f4fa566d3a12fbc74db",
      "placeholder": "​",
      "style": "IPY_MODEL_aa9e1adbb03145bf9f7303f483ef092d",
      "value": "generation_config.json: 100%"
     }
    },
    "c522b77d01134c649471efe63081b70a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c840f95653e84e999011bd481e5d8881": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f0cefb763aa94a209afc519404be0937",
       "IPY_MODEL_9b501878974e40cba80b6c1720136f53",
       "IPY_MODEL_947b1247612a4b749d47ec642038b55f"
      ],
      "layout": "IPY_MODEL_c522b77d01134c649471efe63081b70a"
     }
    },
    "cb16691066414234b3fe425cc2672009": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cc369449ffff43deb63f4a3412e18b03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_367025ffd0974fb8b152243c87e9fd53",
      "max": 2539,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_62d656ee7be5498389d2c913a2335bfc",
      "value": 2539
     }
    },
    "d5f28c59c40b41abb5251f918d209d8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d69b1b7cc42e4ddfb5bf82a90cec54bf",
      "placeholder": "​",
      "style": "IPY_MODEL_396d5bf0883e426c9acd44a9b8167573",
      "value": " 2.54k/2.54k [00:00&lt;00:00, 21.4kB/s]"
     }
    },
    "d69b1b7cc42e4ddfb5bf82a90cec54bf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2f93dc6476b4163bd0c343d7ef0a1ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e4eb74bd4f6a4db29c725cc78a37c7e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e61e6a8645dd449984a74bc8549b562f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e9a69dd13c45432eaf46e81c6932fa37": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea3ca0e907a347a192639933cfd62b0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_52932579c6534df1a3ff5917e56a9da4",
      "max": 147,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_46cdfb91bdd24b1098ffaf3e372212b7",
      "value": 147
     }
    },
    "ee063e069bd54cd6b04c28b98994e1dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f0cefb763aa94a209afc519404be0937": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e338023bb864b179d90885a058cbd20",
      "placeholder": "​",
      "style": "IPY_MODEL_cb16691066414234b3fe425cc2672009",
      "value": "model.safetensors: 100%"
     }
    },
    "f1f6207f4e9341dfb6504dee0203ddb6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_458e2e308fde4f688a0ec867beddea49",
      "placeholder": "​",
      "style": "IPY_MODEL_1fa53b1b77354089a72ebc464d831796",
      "value": "tokenizer.json: 100%"
     }
    },
    "f286947f27704ca0b17983da5bee9ec2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2877dfb910641ae8ac4af8afdc47ef1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a2bda5e229664440b18c1dcae58c0521",
      "placeholder": "​",
      "style": "IPY_MODEL_9c319e6538134d128b82ba57f2363ba7",
      "value": " 2.20k/2.20k [00:00&lt;00:00, 63.1kB/s]"
     }
    },
    "f526cb7ab7b643c4ac199f235123d7b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fd6e6129457842a29fc1306451c323dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
